# This is example inventory file!
# Please specify the ip addresses and connection settings for your environment
# The specified ip addresses will be used to listen by the cluster components.

# "postgresql_exists='true'" if PostgreSQL is already exists and running
# "hostname=" variable is optional (used to change the server name)

# if dcs_exists: false and dcs_type: "etcd" (in vars/main.yml)
[consul_instances]  # recommendation: 3 or 5-7 nodes
ansibledb01 consul_iface=enp0s8 consul_node_role=server consul_bootstrap_expect=true
ansibledb02 consul_iface=enp0s8 consul_node_role=server consul_bootstrap_expect=true
ansibledb03 consul_iface=enp0s8 consul_node_role=server consul_bootstrap_expect=true


# if with_haproxy_load_balancing: true (in vars/main.yml)
[balancers]
ansiblepx01
ansiblepx02


# PostgreSQL nodes
[master]
10.10.10.10 hostname=ansibledb01 postgresql_exists='false'

[replica]
10.10.10.11 hostname=ansibledb02 postgresql_exists='false'
10.10.10.12 hostname=ansibledb03 postgresql_exists='false'

[postgres_cluster:children]
master
replica


# In this example, all components will be installed on PostgreSQL nodes
# You can deploy the etcd cluster and the haproxy balancers on other dedicated servers. 


# if pgbackrest_install: true and "repo_host" is set (in vars/main.yml)
[pgbackrest]  # optional (Dedicated Repository Host)


# Connection settings
[all:vars]
ansible_connection='ssh'
ansible_ssh_port='22'
ansible_user='ansibledb'
ansible_ssh_pass='1'  # "sshpass" package is required for use "ansible_ssh_pass"
# ansible_ssh_private_key_file=
# ansible_python_interpreter='/usr/bin/python3'  # is required for use python3

[pgbackrest:vars]
ansible_user='ansibledb'
ansible_ssh_pass='1'

